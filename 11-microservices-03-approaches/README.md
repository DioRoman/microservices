
# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.

## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

## Ответ

Для обеспечения процесса разработки в микросервисной архитектуре с учетом всех заданных требований можно предложить комплексное решение на базе облачной платформы GitLab CI/CD.

## Основные компоненты решения

- Хранение исходного кода: облачная Git-система (GitLab), с организацией отдельного репозитория на каждый микросервис. Такой подход обеспечивает автономность разработки, разные права доступа и облегчает управление версиями каждого сервиса отдельно.
- Контроль версий: GitLab основан на Git, удовлетворяет требованию использования Git.
- Непрерывная интеграция и поставка (CI/CD): встроенный механизм GitLab CI позволяет запускать сборки по событию (push, pull request) и вручную с указанием параметров, а также создавать шаблоны и настраивать кастомные шаги в файлах .gitlab-ci.yml.
- Безопасное хранение секретных данных: встроенная секция GitLab CI/CD Secrets позволяет безопасно хранить пароли и ключи доступа, доступные только для определённых сборок.
- Варианты сборок из одного репозитория и параллельные запуски: GitLab CI поддерживает несколько конфигураций (например, для разных веток или параметров), параллельный запуск нескольких сборок и тестов с помощью настройки параллельных джобов.
- Докеризация: поддержка собственных докер-образов для сборки проектов, настройка Docker executor в GitLab Runner.
- Развертывание агентов на собственных серверах: GitLab Runner поддерживает регистрацию и запуск агентов (раннеров) на любом сервере, что позволяет гибко масштабировать инфраструктуру.
- Параллельный запуск тестов и сборок: реализуется конфигурацией parallel jobs в .gitlab-ci.yml, что ускоряет общий процесс сборки и тестирования.

## Обоснование выбора GitLab CI/CD

- Полностью облачная платформа с комплексной поддержкой Git, CI/CD, секретов и докеризации.
- Широкие возможности настройки процессов сборки с шаблонами, параметрами, кастомными шагами и триггерами.
- Поддержка многообразных сценариев — от простых сборок до сложных многопоточныx pipeline.
- Безопасное хранение секретных данных и интеграция с внешними хранилищами секретов (например, HashiCorp Vault).
- Возможность использования собственных Docker-образов и развертывание CI-агентов на своих серверах для соблюдения требований безопасности и производительности.
- Параллелизм в сборках и тестах, что ускоряет цикл разработки.

Таким образом, GitLab CI/CD удовлетворяет всем требованиям задачи, позволяя организовать гибкую, масштабируемую и безопасную инфраструктуру разработки и эксплуатации микросервисов, основанных на Git и Docker.

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

## Ответ

Для обеспечения сбора и анализа логов микросервисов в распределенной архитектуре оптимальным решением является использование централизованного стекa ELK (Elasticsearch, Logstash, Kibana) или его распространенного варианта с Fluentd/Fluent Bit вместо Logstash, вместе с обеспечением гарантированной доставки логов.

## Компоненты решения

- Сбор логов из stdout всех сервисов на каждом хосте осуществляется с помощью агентов сбора логов, например, Fluentd или Fluent Bit. Они минимально нагружают приложения, работают с чистым логами из stdout и форматируют их в структуру для передачи.
- Для гарантирования доставки (надежной доставки) используется буферизация логов на агенте и повторные попытки отправки в центральное хранилище (Elasticsearch). Это обеспечивает отсутствие потерь при сбоях сети или хостов.
- Центральное хранилище логов — Elasticsearch. Оно масштабируемо, поддерживает полнотекстовый поиск, фильтрацию и агрегацию данных.
- Для анализа и поиска используется Kibana — удобный веб-интерфейс, предоставляющий разработчикам доступ к поиску, фильтрации и визуализации логов.
- В Kibana можно создавать сохраненные поиски и делиться ссылками на них, позволяя быстро обращаться к нужным наборам данных.
- Logstash, или Fluentd/Fluent Bit, отвечает за парсинг, фильтрацию и отправку логов в Elasticsearch, обеспечивая гибкую обработку и трансформацию.

## Обоснование выбора

- ELK стек (или его вариации) является отраслевым стандартом для сбора, агрегирования и анализа логов в микросервисных средах.
- Агенты Fluentd/Fluent Bit минимально требуют изменений в приложениях — собирают логи из stdout без сложной интеграции.
- Гарантированная доставка достигается за счет надежных агентов с буферизацией.
- Elasticsearch отлично удовлетворяет запросам на поиск, фильтрацию и масштабируемость.
- Kibana предоставляет удобный, доступный для разработчиков пользовательский интерфейс с поддержкой сохраненных поисков и совместного доступа.
- Решение масштабируемо и подходит как для небольших, так и для больших систем с сотнями микросервисов.

Таким образом, предложение — использовать Fluentd/Fluent Bit на каждом хосте для сбора логов из stdout микросервисов, централизованное хранилище на базе Elasticsearch и Kibana для анализа и визуализации с возможностью делиться поисками и предоставить доступ разработчикам через Kibana.

Если требуется, могу дополнительно описать пример конфигурации сбора и анализа логов в такой архитектуре.Для сбора и анализа логов микросервисов предлагается централизованное решение на базе стека ELK (Elasticsearch, Logstash/Fluentd, Kibana):

- Агенты Fluentd или Fluent Bit на всех хостах собирают логи напрямую из stdout микросервисов с минимальными требованиями к изменениям в приложениях.
- Для гарантированной доставки логи буферизуются на агентах с повторной отправкой в случае сбоев.
- Elasticsearch служит масштабируемым центральным хранилищем с поддержкой полнотекстового поиска, фильтрации и агрегаций.
- Kibana предоставляет разработчикам удобный веб-интерфейс для поиска, фильтрации и визуализации логов с возможностью сохранять и делиться ссылками на поиски.

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

## Ответ

Для мониторинга состояния хостов и микросервисов в распределённой архитектуре оптимальным решением является использование связки Prometheus и Grafana.

## Компоненты решения

- Prometheus — система сбора метрик, которая периодически (pull-модель) опрашивает все хосты и сервисы по HTTP-эндпоинту (/metrics) для получения метрик состояния ресурсов и специфичных для сервисов, включая CPU, RAM, HDD, сеть и другие показатели.
- Node Exporter — агент на каждом хосте, собирающий метрики операционной системы, такие как загрузка CPU, память, диск и сеть.
- Специфичные метрики сервисов — экспонируются самими сервисами через встроенные или сторонние экспортеры (например, custom exporters, client libraries для Prometheus).
- Grafana — платформа визуализации, которая подключается к Prometheus как источнику данных и предоставляет удобный пользовательский интерфейс для создания настраиваемых панелей, составления запросов и агрегирования метрик.
- Настраиваемые панели позволяют создавать дашборды для мониторинга всей системы и отдельных сервисов.
- Можно гибко делать запросы к метрикам на основе языка PromQL, что обеспечивает глубокий и точный анализ данных.

## Обоснование выбора

- Prometheus является стандартом де-факто для мониторинга микросервисных и контейнеризованных сред благодаря легковесности, возможности расширения и мощному языку запросов PromQL.
- Node Exporter обеспечивает сбор ключевых системных метрик с минимальными накладными расходами.
- Собственные метрики сервисов позволяют измерять бизнес- и технические показатели на уровне каждого микросервиса.
- Grafana предлагает удобный, гибкий и мощный веб-интерфейс для визуализации и анализа метрик с возможностью настраивать разные дашборды под нужды команды.
- Открытый исходный код, большое сообщество и богатая экосистема плагинов делают связку устойчивым и расширяемым решением.

Таким образом, Prometheus + Node Exporter + Grafana создают мощную систему мониторинга, которая отвечает всем поставленным требованиям по сбору, хранению, анализу и визуализации метрик микросервисной архитектуры.
 
## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
